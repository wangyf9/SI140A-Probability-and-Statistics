{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Monte Carlo Tree Search Mini Problem Set\n",
    "\n",
    "- In this project, you will learn and implement the Monte Carlo Tree Search (MCTS) algoritm on the Tic Tac Toe game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a tree search?\n",
    "Trees are a special case of the graph problems previously seen in class. For example, consider Tic Tac Toe. From the starting blank board, each choice of where to draw an X is a possible future, followed by each choice of where to draw an O. A planner can look at this sprawl of futures and choose which action will most likely lead to victory.\n",
    "\n",
    "![Example 1](./figures/example_1.png)\n",
    "\n",
    "## Breadth First Tree Search\n",
    "\n",
    "In a breadth first tree search the planner considers potential boards in order of depth. All boards that are one turn in the future are considered first, followed by the boards two turns away, until every potential board has been considered. The planner then chooses the best move to make based on whether the move will lead to victory or to defeat. In the following example, a breadth first search would identify that all other moves lead to a loss and instead pick the rightmost move.\n",
    "\n",
    "![Example 2](./figures/example_2.png)\n",
    "\n",
    "## Monte Carlo Tree Search\n",
    "\n",
    "The problem with breadth first search is that it isn't at all clever. Tic Tac Toe is one of the simpler games in existence, but there are nearly three-hundred sixty thousand possible sets of moves for a BFS-based planner to consider. In a game with less constrained movement, like chess, this number exceeds the number of atoms in the known universe after looking only a couple of turns into the future. A Breadth First Search is too tied up with being logical and provably correct. Monte Carlo Tree Search leaps ahead to impulsively go where no search has gone before. In simpler terms, BFS is Spock while MCTS is Kirk.\n",
    "\n",
    "MCTS performs its search by repeatedly imagining play-throughs of the game or scenario, traveling down the entire branch of the game tree until it terminates. Based on how this play-through went, MCTS then updates the value of each node (move) involved based on whether it won or lost the playthrough. The Monte Carlo component comes from the fact that it chooses moves at random, not based on heuristics or visit count. This nondeterminism greatly increases the potential space it can explore even though its exploration will be much less rigorous.\n",
    "\n",
    "For example, let's look at the BFS tree above. The bad red moves have a high probability of loss because in 1/5 of the playthroughs X will instantly win. The correct, rightmost move will have a lower probability of a loss because X doesn't have this 1/5 chance of winning. MCTS will discard the red moves because of this higher loss probability, assigning them lower values whenever it selects them during a randomized play-through.\n",
    "\n",
    "## MCTS Algorithm\n",
    "\n",
    "[Check out the paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6145622&tag=1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you write your very own MCTS bot, you need to get sped up on the API you will be using. But even before getting into the API, please run the following to import the API and some boilerplate code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import algo\n",
    "import sim\n",
    "import random\n",
    "import time\n",
    "from tests import *\n",
    "from game import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `Board` Class\n",
    "\n",
    "The `Board` class is a template class that represents the state of a\n",
    "board at a single point in a game. We've created a `ConnectFourBoard`\n",
    "subclass that handles the mechanics for you. For any `Board` instance\n",
    "`board`, you have access to the following methods:\n",
    "\n",
    "**`board.get_legal_actions()`:** Returns a python set of `Action` class\n",
    "instances. Each element in the set is a valid action that can be applied\n",
    "to the `board` to create a new `Board` instance. See the `Action` API\n",
    "section below.\n",
    "\n",
    "**`board.is_terminal()`:** Returns `True` if `board` is an endgame board.\n",
    "Returns `False` otherwise.\n",
    "\n",
    "**`board.current_player_id()`:** Returns an integer that represents which player\n",
    "is expected to play next. For example, if this method returns 0, then the player\n",
    "who is the first player in some simulation of a game should be the next one to\n",
    "play an action. This is used internally in the `Simulation` class for bookkeeping,\n",
    "but you will need it when you do the backup step of the MCTS algorithm.\n",
    "\n",
    "**`board.reward_vector()`:** Returns a $n$-element tuple, where $n$ is the number\n",
    "of players, that contains the rewards earned by each player at this particular\n",
    "`board`. For Connect Four, $n=2$. Thus this method may return something like\n",
    "`(1,-1)`, meaning the player with ID 0 had a reward of 1, and the player with ID\n",
    "1 has reward -1.\n",
    "\n",
    "### The `Action` Class\n",
    "\n",
    "The `Action` class is for representing a single action that is meant to alter a\n",
    "`board`. We have written a `ConnectFourAction` subclass for you. Instances\n",
    "are hashable, so to check if two actions are the same, `hash(action1) == hash(action2)`\n",
    "can be used.\n",
    "For any `Action`\n",
    "instance `action`, you will only need the following method:\n",
    "\n",
    "**`action.apply(board)`:** Given a `Board` instance `board`, returns a new\n",
    "`Board` instance that represents the board after that action has been\n",
    "performed. If the `action` cannot be applied, an error is thrown.\n",
    "\n",
    "### The `Node` Class\n",
    "\n",
    "The `Node` class represents a single node in the MCTS tree that is constructed\n",
    "during each iteration of the algorithm. You will be interacting with this class\n",
    "the most. If you remember the algorithm, each node contains certain pieces of\n",
    "information that's associated with it. For any `Node` instance `node`, you have\n",
    "the following methods at you disposal:\n",
    "\n",
    "**`Node(board, action, parent)`**: The constructor takes three arguments.\n",
    "First, a `Board` instance `board` that the node will represent. Second,\n",
    "an `Action` instance 'action' that represents the incoming action that created\n",
    "`board`. Finally, a `Node` instance `parent`. For a root node, you would\n",
    "pass `None` in for both `action` and `parent`.\n",
    "\n",
    "**`node.get_board()`:** Returns the `Board` instance that `node` is representing.\n",
    "\n",
    "**`node.get_action()`:** Returns the incoming `Action` instance.\n",
    "\n",
    "**`node.get_parent()`:** Returns the parent `Node` instance.\n",
    "\n",
    "**`node.get_children()`:** Returns a list of `Node` instances that represent\n",
    "the children that have been expanded thus far.\n",
    "\n",
    "**`node.add_child(child)`:** Add a `Node` instance `child` to the list of expanded\n",
    "children under `node`.\n",
    "\n",
    "**`node.get_num_visits()`:** Returns the number of times `node` has been visited.\n",
    "\n",
    "**`node.get_player_id()`:** This just returns `board.current_player_id()`, where\n",
    "`board` is the board that was passed into the constructor.\n",
    "\n",
    "**`node.q_value()`:** Returns the total reward that the `node` has accumulated.\n",
    "This reward is contained in a variable `node.q` that you can access if it needs\n",
    "to be changed during the algorithm.\n",
    "\n",
    "**`node.visit()`:** Doesn't return anything, but increments the internal counter\n",
    "that keeps track of how many times the `node` has been visited.\n",
    "\n",
    "**`node.is_fully_expanded()`:** Return `True` is all children that can be reached\n",
    "from this node have been expanded. Returns `False` otherwise.\n",
    "\n",
    "**`node.value(c)`**: Returns the calculated UCT value for this node. The parameter\n",
    "`c` is the _exploration_ constant.\n",
    "\n",
    "### The `Player` Class\n",
    "\n",
    "The `Player` class represents, you guessed it, a player. You won't have to actually\n",
    "deal with this class at all in this problem set. It exists for running the\n",
    "simulation at the end. However, if you interested, you may look at `game.py`\n",
    "to see what methods are used.\n",
    "\n",
    "### The `Simulation` Class\n",
    "\n",
    "The `Simulation` class is used for setting up a simulation for multiple\n",
    "players to play a game. You again don't need to worry about this class, as it\n",
    "is for running the simulation at the end. Refer to `game.py` if your curious\n",
    "about how it works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Set Code\n",
    "In the following parts, we will ask you to implement the Monte Carlo Tree Search algorithm to beat the bot. You will be implementing the pseudocode starting on page 10 of the [MCTS paper](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6145622&tag=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Policy\n",
    "The first step is to implement the default policy, which plays through an entire game session. It chooses actions at random, applying them to the board until the game is over. It then returns the reward vector of the finished board.\n",
    "\n",
    "<img src=\"figures/default-policy.png\" alt=\"Default Policy Pseudocode\" width=\"350px\"/><br/>\n",
    "<center><em><small>Browne, et al.</small></em></center>\n",
    "\n",
    "**Note:** You can use `random.choice(my_list)` to select a random item from `my_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# randomly picking moves to reach the end game\n",
    "# Input: BOARD, the board that we want to start randomly picking moves\n",
    "# Output: the reward vector when the game terminates\n",
    "#######################################################################\n",
    "def default_policy(board):\n",
    "    # TODO\n",
    "    while board.is_terminal() == False:#NOT A endgame\n",
    "        board = random.choice(list(board.get_legal_actions())).apply(board)\n",
    "    return board.reward_vector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test passed\n",
      "Exception occured testing default_policy on board:\n",
      "5 R - R - R R R\n",
      "4 X X X X X R X\n",
      "3 R X R X R R R\n",
      "2 R X R X R X R\n",
      "1 R R R R R R R\n",
      "0 X R X R X R X\n",
      "  0 1 2 3 4 5 6\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Tuples differ: (1, -1) != (-1, 1)\n\nFirst differing element 0:\n1\n-1\n\n- (1, -1)\n?     -\n\n+ (-1, 1)\n?  +\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_default_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_policy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\概率论final\\Final project\\MCTS project\\tests.py:7\u001b[0m, in \u001b[0;36mtest_default_policy\u001b[1;34m(default_policy)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_default_policy\u001b[39m(default_policy):\n\u001b[0;32m      6\u001b[0m     test_default_policy_simple_win(default_policy)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mtest_default_policy_simple_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdefault_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     test_default_policy_termination(default_policy)\n\u001b[0;32m      9\u001b[0m     print_ok()\n",
      "File \u001b[1;32m~\\Desktop\\概率论final\\Final project\\MCTS project\\tests.py:84\u001b[0m, in \u001b[0;36mtest_default_policy_simple_loss\u001b[1;34m(default_policy)\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException occured testing default_policy on board:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m     board\u001b[38;5;241m.\u001b[39mvisualize()\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Desktop\\概率论final\\Final project\\MCTS project\\tests.py:63\u001b[0m, in \u001b[0;36mtest_default_policy_simple_loss\u001b[1;34m(default_policy)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     reward \u001b[38;5;241m=\u001b[39m default_policy(board)\n\u001b[1;32m---> 63\u001b[0m     \u001b[43massert_equal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     assert_equal(\u001b[38;5;28mlen\u001b[39m(spy\u001b[38;5;241m.\u001b[39mapplications), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# Red turn apply()\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\unittest\\case.py:837\u001b[0m, in \u001b[0;36mTestCase.assertEqual\u001b[1;34m(self, first, second, msg)\u001b[0m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;124;03m\"\"\"Fail if the two objects are unequal as determined by the '=='\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;124;03m   operator.\u001b[39;00m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    836\u001b[0m assertion_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getAssertEqualityFunc(first, second)\n\u001b[1;32m--> 837\u001b[0m \u001b[43massertion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\unittest\\case.py:1054\u001b[0m, in \u001b[0;36mTestCase.assertTupleEqual\u001b[1;34m(self, tuple1, tuple2, msg)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massertTupleEqual\u001b[39m(\u001b[38;5;28mself\u001b[39m, tuple1, tuple2, msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;124;03m\"\"\"A tuple-specific equality assertion.\u001b[39;00m\n\u001b[0;32m   1047\u001b[0m \n\u001b[0;32m   1048\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;124;03m                differences.\u001b[39;00m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1054\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massertSequenceEqual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuple1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuple2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\unittest\\case.py:1025\u001b[0m, in \u001b[0;36mTestCase.assertSequenceEqual\u001b[1;34m(self, seq1, seq2, msg, seq_type)\u001b[0m\n\u001b[0;32m   1023\u001b[0m standardMsg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_truncateMessage(standardMsg, diffMsg)\n\u001b[0;32m   1024\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_formatMessage(msg, standardMsg)\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\unittest\\case.py:676\u001b[0m, in \u001b[0;36mTestCase.fail\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfail\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;124;03m\"\"\"Fail immediately, with the given message.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 676\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfailureException(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Tuples differ: (1, -1) != (-1, 1)\n\nFirst differing element 0:\n1\n-1\n\n- (1, -1)\n?     -\n\n+ (-1, 1)\n?  +\n"
     ]
    }
   ],
   "source": [
    "test_default_policy(default_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Policy\n",
    "\n",
    "<img src=\"figures/tree-policy.png\" alt=\"Tree Policy Pseudocode\" width=\"250px\"/><br/>\n",
    "<center><em>Tree Policy Pseudocode (Browne, et al.)</em></center>\n",
    "\n",
    "\n",
    "The tree policy performs a depth-first search of the tree using `best_child` and `expand`. If it encounters an unexpanded node it will return the expanded child of that node. Otherwise, it continues its search in the best child of the current node.\n",
    "\n",
    "The `best_child` function find the best child node if a node is fully expanded. It also takes the exploitation constant as an argument.\n",
    "\n",
    "The `expand` function expands a node that has unexpanded children. It must get all current children of the node and all possible children of the node then add one of the possible children to the node. It should then return this newly added child."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Child\n",
    "<img src=\"figures/best-child.png\" alt=\"Best Child Pseudocode\" width=\"400px\"/><br/>\n",
    "<center><em><small>Browne, et al.</small></em></center>\n",
    "\n",
    "**Note:** For convenience, we've implemented a function that returns the heuristic inside the max operator. Look at the function `node.value(c)` for the `NODE` class API and save yourself the headache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# get the best child from this node (using heuristic)\n",
    "# Input: NODE, the node we want to find the best child of\n",
    "#        C,    the exploitation constant\n",
    "# Output: the child node\n",
    "###########################################################\n",
    "def best_child(node, c):\n",
    "    childs = node.get_children()\n",
    "    value = -9999\n",
    "    ret_child = None\n",
    "    for child in childs:\n",
    "        if child.value(c) > value:\n",
    "            value = child.value(c)\n",
    "            ret_child = child\n",
    "    return ret_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_best_child(best_child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand\n",
    "<img src=\"figures/expand.png\" alt=\"Expand Pseudocode\" width=\"400px\"/><br/>\n",
    "<center><em><small>Browne, et al.</small></em></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# expand a node since it is not fully expanded\n",
    "# Input: NODE, a node that want to be expanded\n",
    "# Output: the child node\n",
    "###########################################################\n",
    "def expand(node):\n",
    "    # TODO\n",
    "    board = node.get_board()\n",
    "    newaction = random.choice(list(board.get_legal_actions()))\n",
    "    subboard = newaction.apply(board)\n",
    "    subchild = Node(subboard,newaction,node)\n",
    "    node.add_child(subchild)\n",
    "    return subchild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_expand(expand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Policy\n",
    "<img src=\"figures/tree-policy.png\" alt=\"Tree Policy Pseudocode\" width=\"250px\"/><br/>\n",
    "<center><em><small>Browne, et al.</small></em></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# heuristically search to the leaf level\n",
    "# Input: NODE, a node that want to search down \n",
    "#        C, the exploitation value\n",
    "# Output: the leaf node that we expand till\n",
    "##########################################################\n",
    "def tree_policy(node, c):\n",
    "    # TODO\n",
    "    while (node.get_board().is_terminal() == False):\n",
    "        if (node.is_fully_expanded() == False):\n",
    "            return expand(node)\n",
    "        else:\n",
    "            node = best_child(node,c)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tree_policy(tree_policy, expand, best_child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup\n",
    "Now its time to make a way to turn the reward from `default_policy` into the information that `tree_policy` needs. `backup` should take the terminal state and reward from `default_policy` and proceed up the tree, updating the nodes on its path based on the reward.\n",
    "\n",
    "<img src=\"figures/backup.png\" alt=\"Backup Pseudocode\" width=\"250px\"/><br/>\n",
    "<center><em><small>Browne, et al.</small></em></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# reward update for the tree after one simulation\n",
    "# Input: NODE, the node that we want to backup from\n",
    "#        REWARD_VECTOR, the reward vector of this exploration\n",
    "# Output: nothing\n",
    "##############################################################\n",
    "def backup(node, reward_vector):\n",
    "    # TODO\n",
    "    while (node != None):\n",
    "        node.visit()\n",
    "        node.q = node.q_value() + reward_vector[node.get_player_id()-1]\n",
    "        node = node.get_parent()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_backup(backup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search (UCT)\n",
    "Time to put everything together! Keep running `tree_policy`, `default_policy`, and `backup` until you run out of time! Finally, return the best child's associated action.\n",
    "\n",
    "<img src=\"figures/uct-search.png\" alt=\"Search Pseudocode\" width=\"300px\"/><br/>\n",
    "<center><em><small>Browne, et al.</small></em></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# monte carlo tree search algorithm using UCT heuristic\n",
    "# Input: BOARD, the current game board\n",
    "#        TIME_LIMIT, the time limit of the calculation in second\n",
    "# Output: class Action represents the best action to take\n",
    "####################################################################\n",
    "def uct(board, time_limit):\n",
    "    start_time = time.time()\n",
    "    root = Node(board, None, None)\n",
    "    while (time.time() - start_time) < time_limit:\n",
    "        # TODO\n",
    "        node = tree_policy(root,3)\n",
    "        newreward = default_policy(node.get_board())\n",
    "        backup(node,newreward)\n",
    "    return best_child(root,0).get_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_uct(uct) # this test takes 15-30 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Final Challenge\n",
    "Time to show Stonn the power of human ingenuity! Win at least 9 out of 10 games to triumph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim.run_final_test(uct)"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
